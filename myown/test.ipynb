{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final_shuffle.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b32e7be9c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataMat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelMat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdatamat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelmat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloadDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'final_shuffle.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatamat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0b32e7be9c4d>\u001b[0m in \u001b[0;36mloadDataSet\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m#general function to parse tab -delimited floats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnumFeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get number of fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdataMat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mlabelMat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_shuffle.txt'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def loadDataSet(fileName):    #general function to parse tab -delimited floats\n",
    "    numFeat = len(open(fileName).readline().split('\\t')) #get number of fields \n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr =[]\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "datamat,labelmat=loadDataSet('final_shuffle.txt')\n",
    "print (np.shape(datamat))\n",
    "\n",
    "from  sklearn.datasets import  load_iris\n",
    "from sklearn.feature_selection import  SelectKBest\n",
    "from sklearn.feature_selection import  chi2\n",
    "\n",
    "#iris=load_iris()\n",
    "x,y=datamat,labelmat\n",
    "x.shape\n",
    "x_new=SelectKBest(chi2,k=10).fit_transform(x,y)\n",
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\YJ\\\\Documents'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ann'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aceaba3c98ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ann'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep  6 08:42:39 2017\n",
    "\n",
    "@author: John\n",
    "\"\"\"\n",
    "\n",
    "import ann\n",
    "import  pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "########全部的特征值###################################3\n",
    "# dataMat1,labelMat=ann.loadDataSet('final_shuffle.txt')\n",
    "# #==============================================================================\n",
    "# # dataArr2,labelArr2=ann.loadDataSet('final_eigen02.txt')\n",
    "# # dataMat1.extend(dataArr2)\n",
    "# # labelMat.extend(labelArr2)\n",
    "# #==============================================================================\n",
    "# labelMat=np.array(labelMat)\n",
    "#\n",
    "#\n",
    "# data01=ann.preprocess(dataMat1)\n",
    "# dataMat=ann.preprocess1(data01)\n",
    "# #dataMat=np.array(data01)\n",
    "# #dataMat=np.array(dataMat1)\n",
    "#\n",
    "# #dataMat=dataMat[:,0:44]\n",
    "########全部的特征值###################################3\n",
    "\n",
    "###################遗传算法降维后的特征值#################\n",
    "dataset=pd.read_csv(\"LR9.csv\")\n",
    "dataset=np.array(dataset)\n",
    "dataMat=dataset[:, 0:9]\n",
    "dataMat=ann.preprocess(dataMat)\n",
    "dataMat=ann.preprocess1(dataMat)\n",
    "labelMat=dataset[:,9]\n",
    "\n",
    "\n",
    "###################遗传算法降维后的特征值#################\n",
    "\n",
    "# import  global_list as gl\n",
    "# dataset=gl.dataSet\n",
    "# dataset=np.array(dataset)\n",
    "# dataMat=dataset[:,0:78]\n",
    "# labelMat=dataset[:,78]\n",
    "\n",
    "# for i in range(len(labelMat)):\n",
    "#     if labelMat[i]==2:\n",
    "#         labelMat[i]=-1;#adaboost只能区分-1和1的标签\n",
    "\n",
    "evaluate_train=[]\n",
    "evaluate_test=[]\n",
    "prenum_train=[]\n",
    "prenum_test=[]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train, test in skf.split(dataMat, labelMat):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    train_in = dataMat[train]\n",
    "    test_in=dataMat[test]\n",
    "    train_out=labelMat[train]\n",
    "    test_out=labelMat[test]\n",
    "    train_in, train_out = RandomUnderSampler().fit_sample(train_in, train_out)\n",
    "    train_predict,test_predict,proba_train,proba_test=ann.ANNClassifier(train_in,train_out,test_in)\n",
    "    proba_train=proba_train[:,1]\n",
    "    proba_test=proba_test[:,1]\n",
    "    test1,test2=ann.evaluatemodel(train_out,train_predict,proba_train)#test model with trainset\n",
    "    evaluate_train.extend(test1)\n",
    "    prenum_train.extend(test2)\n",
    "    \n",
    "    test3,test4=ann.evaluatemodel(test_out,test_predict,proba_test)#test model with testset\n",
    "    evaluate_test.extend(test3)\n",
    "    prenum_test.extend(test4)\n",
    "    \n",
    "mean_train=np.mean(evaluate_train,axis=0)\n",
    "std_train=np.std(evaluate_train,axis=0)\n",
    "evaluate_train.append(mean_train)\n",
    "evaluate_train.append(std_train)\n",
    "\n",
    "mean_test=np.mean(evaluate_test,axis=0)\n",
    "std_test=np.std(evaluate_test,axis=0)\n",
    "evaluate_test.append(mean_test)\n",
    "evaluate_test.append(std_test)\n",
    "    \n",
    "evaluate_train=np.array(evaluate_train)\n",
    "evaluate_test=np.array(evaluate_test)\n",
    "prenum_train=np.array(prenum_train)\n",
    "prenum_test=np.array(prenum_test)\n",
    "\n",
    "evaluate_train_mean=np.mean(evaluate_test,axis=0)\n",
    "#np.array(test_important)\n",
    "print(\"view the variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
